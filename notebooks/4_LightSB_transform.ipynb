{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d90f645",
   "metadata": {},
   "source": [
    "# Light Schrödinger Bridge Night to Day Domain Transform\n",
    "\n",
    "This notebooks trains the LightSB model using the AutoencoderKL latents we generated. It will perform a grid search over the n_potentials, is_diagonal and epsilon parameters to get the best performing model.\n",
    "\n",
    "Next, it performs a transformation on the night validation set. Finally, we decode these latents back into images using the encoder and save them separately to the data folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbe3f99",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f583efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "# if colab, mount drive and get the git repo\n",
    "if 'google.colab' in sys.modules:\n",
    "    from google.colab import drive\n",
    "    print(os.getcwd())\n",
    "    drive.mount('/content/drive')\n",
    "    !git clone --recurse-submodules https://github.com/jsluijter02/LightSB_YOLO\n",
    "\n",
    "    # Append LightSB_YOLO path\n",
    "    sys.path.append(os.path.join(os.getcwd(), 'LightSB_YOLO'))\n",
    "\n",
    "    ## TODO: \n",
    "\n",
    "# otherwise local path append\n",
    "else:\n",
    "    sys.path.append(os.path.dirname(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e06e109",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/lightsb_yolo/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/opt/anaconda3/envs/lightsb_yolo/lib/python3.8/site-packages/torch/amp/autocast_mode.py:265: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "from argparse import Namespace\n",
    "import copy\n",
    "import torch\n",
    "import diffusers\n",
    "from datetime import date\n",
    "\n",
    "from scripts.utils import dirs\n",
    "dirs.add_LIGHTSB_to_PATH()\n",
    "\n",
    "from scripts.models.autoencoderkl import AutoencoderKL_BDD\n",
    "from scripts.models.lightsb import LightSB_BDD\n",
    "from scripts.evals.FID import latent_FID_score, image_FID_score\n",
    "from scripts.utils import img\n",
    "from scripts.utils.device import get_device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55922ea1",
   "metadata": {},
   "source": [
    "## Encoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43661621",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = AutoencoderKL_BDD()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e360558",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51d42f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36800, 4096)\n",
      "train_night_latents shape:  (28028, 4096)\n",
      "val_day_latents shape:  (5258, 4096)\n",
      "val_night_latents shape:  (3929, 4096)\n",
      "val_night_filenames length:  3929\n"
     ]
    }
   ],
   "source": [
    "data_dir = dirs.get_data_dir()\n",
    "latent_dir = os.path.join(data_dir, \"encodings\")\n",
    "\n",
    "# Only save Val_night file names -> others are redundant\n",
    "train_day_latents, _  = encoder.load_latents(os.path.join(latent_dir, \"train_day.npz\"))\n",
    "print(train_day_latents.shape)\n",
    "\n",
    "train_night_latents, _ = encoder.load_latents(os.path.join(latent_dir, \"train_night.npz\"))\n",
    "print(\"train_night_latents shape: \", train_night_latents.shape)\n",
    "\n",
    "val_day_latents, _ = encoder.load_latents(os.path.join(latent_dir, \"val_day.npz\"))\n",
    "print(\"val_day_latents shape: \", val_day_latents.shape)\n",
    "\n",
    "val_night_latents, val_night_filenames = encoder.load_latents(os.path.join(latent_dir, \"val_night.npz\"))\n",
    "print(\"val_night_latents shape: \", val_night_latents.shape)\n",
    "print(\"val_night_filenames length: \", len(val_night_filenames))\n",
    "\n",
    "np_data = {\"train_day\": train_day_latents, \n",
    "           \"train_night\": train_night_latents, \n",
    "           \"val_day\": val_day_latents, \n",
    "           \"val_night\": val_night_latents}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a78add",
   "metadata": {},
   "source": [
    "## Load Light Schrödinger Bridge model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b6fad36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sb_config = LightSB_BDD.standard_config()\n",
    "# sb = LightSB_BDD(sb_config, np_data=np_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3ebc52",
   "metadata": {},
   "source": [
    "## Train SB with a Grid Search + Val Set Evaluation\n",
    "To get a sense of parameter's effectiveness on the transformation, this step performs a grid search and saves the best parameters and state dictionary.\n",
    "\n",
    "Evaluation method: FID on latents.\n",
    "\n",
    "Due to computational and time constraints, it is not possible to transform ALL images six times and produce FID-scores, so a latent-based proxy is taken to determine final LightSB model parameters. FID metric on images will be taken of the final image set.\n",
    "\n",
    "This is different from actual FID metric, as this takes the metric on features learned from a CNN.\n",
    "\n",
    "Additionally, downstream, the mAP of the YOLOPX algorithm will determine this method's succesfullness as a preprocessing step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fe617d",
   "metadata": {},
   "source": [
    "### Grid Search Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bdbf88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilons = [0.01, 0.1, 0.5]\n",
    "n_potentials = [10, 20]\n",
    "is_diagonal = ... # Doesn't work on mac, but it \n",
    "max_steps = [1000, 10000, 50000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ef8b4d",
   "metadata": {},
   "source": [
    "### Grid Search Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "798a2326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# args = Namespace()\n",
    "\n",
    "# models = {}\n",
    "# fid_scores = {}\n",
    "# sample_indices = img.sample_indices(len(sb.X_test), how_many=5)\n",
    "\n",
    "# best = {\n",
    "#     \"name\": None,\n",
    "#     \"fid\": None,\n",
    "#     \"state_dict\": None,\n",
    "#     \"epsilon\" : None,\n",
    "#     \"max_steps\": None,\n",
    "#     \"n_potentials\": None\n",
    "# }\n",
    "\n",
    "# date = date.today().strftime('%Y%m%d')\n",
    "# runs_path = os.path.join(dirs.get_base_dir(), \"runs\", \"LightSB_GridSearch\", date)\n",
    "# os.makedirs(runs_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398043c7",
   "metadata": {},
   "source": [
    "### Grid Search Loop + Internal Val Set Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25c34347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for eps in epsilons:\n",
    "#     for potential in n_potentials:\n",
    "#         for steps in max_steps:\n",
    "#             print(\"Started process for: \", steps, \" \", eps, \" \", potential)\n",
    "#             # to reduce training time, reduce steps to 1000\n",
    "#             args.MAX_STEPS = steps\n",
    "#             args.EPSILON = eps\n",
    "#             args.N_POTENTIALS = potential\n",
    "\n",
    "#             print(\"Reloading model\")\n",
    "#             sb.update_config(args=args)\n",
    "#             sb.reload_model()\n",
    "#             print(\"Reloaded model\")\n",
    "\n",
    "#             print(\"Training model\")\n",
    "#             sb.train()\n",
    "#             print(\"Trained model\")\n",
    "\n",
    "#             print(\"Transforming Validation Latents\")\n",
    "#             transformed = sb.transform(sb.X_test)\n",
    "\n",
    "#             fid = latent_FID_score(transformed, sb.Y_test)\n",
    "#             print(\"FID-score on latents: \", fid)\n",
    "\n",
    "#             state_dict = copy.deepcopy(sb.model.state_dict())\n",
    "\n",
    "#             save = {\n",
    "#                 \"fid\": fid,\n",
    "#                 \"state_dict\": state_dict,\n",
    "#                 \"max_steps\": steps,\n",
    "#                 \"epsilon\": eps,\n",
    "#                 \"n_potentials\": potential\n",
    "#             }\n",
    "\n",
    "#             model_name = f'{fid}_{eps}_{potential}_{steps}.pt'\n",
    "\n",
    "#             torch.save(save, os.path.join(runs_path, model_name))\n",
    "\n",
    "#             # Save highest FID score's params\n",
    "#             if fid > best[\"fid\"]:\n",
    "#                 best[\"fid\"] = fid\n",
    "#                 best[\"epsilon\"] = eps\n",
    "#                 best[\"max_steps\"] = steps\n",
    "#                 best[\"n_potentials\"] = potential\n",
    "#                 best[\"name\"] = model_name\n",
    "#                 best[\"state_dict\"] = state_dict\n",
    "\n",
    "#             sample_imgs = diffusers.utils.pt_to_pil(encoder.decode_latents(transformed[sample_indices]))\n",
    "#             img.plot_samples(sample_imgs, title=f'Transformed Val Set Images with Params: Steps: {steps}, Epsilon: {eps}, N_potentials: {potential}. FID: {fid}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da8200a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'Best model: {best[\"name\"]}, FID: {best[\"fid\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e57e37b",
   "metadata": {},
   "source": [
    "## Transform Val Images with Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c0a3158",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_cfg = LightSB_BDD.standard_config()\n",
    "best_cfg.MODEL.EPSILON = 0.1#best[\"epsilon\"]\n",
    "best_cfg.MODEL.N_POTENTIALS = 20#best[\"n_potentials\"]\n",
    "best_cfg.MAX_STEPS = 10000#best[\"max_steps\"]\n",
    "\n",
    "best_sb = LightSB_BDD(config=best_cfg, np_data=np_data)\n",
    "\n",
    "# best_sb.load_state_dict(best[\"state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0404be62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [02:40<00:00, 62.30it/s]\n"
     ]
    }
   ],
   "source": [
    "best_sb.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88dd6ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_transformed = best_sb.transform(best_sb.X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b547acd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(dirs.get_data_dir(), \"LightSB_transformed.npy\"), best_transformed.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdc2d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latents shape:  torch.Size([3929, 4096])\n",
      "reshaped latents shape:  torch.Size([3929, 4, 32, 32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 246/246 [08:33<00:00,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoded latents shape:  torch.Size([3929, 3, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_transformed = torch.as_tensor(np.load(os.path.join(dirs.get_data_dir(), \"LightSB_transformed.npy\")), device=get_device())\n",
    "decoded = encoder.decode_latents(best_transformed, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3999fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(dirs.get_data_dir(), \"LightSB_decoded.npy\"), decoded.cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5a0f4f",
   "metadata": {},
   "source": [
    "## Save Images to Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66303778",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded = torch.as_tensor(np.load(os.path.join(dirs.get_data_dir(), \"LightSB_decoded.npy\")), device=get_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b48a51eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3929it [00:01, 1982.43it/s]\n"
     ]
    }
   ],
   "source": [
    "encoder.save_imgs(decoded, filenames=val_night_filenames, folder_name=\"LightSB_Images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf273959",
   "metadata": {},
   "source": [
    "## Get ACTUAL Val Night FID Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb56b572",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Day / Day FID\n",
    "## Night / Day FID\n",
    "## Day / Fake Day FID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10773f39",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lightsb_yolo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
